{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fedb915",
   "metadata": {},
   "source": [
    "# Домашнее задание\n",
    "\n",
    "Будем практиковаться на датасете недвижимости (sklearn.datasets.fetch_california_housing)\n",
    "\n",
    "Ваша задача:\n",
    "1. Создать Dataset для загрузки данных\n",
    "2. Обернуть его в Dataloader\n",
    "3. Написать архитектуру сети, которая предсказывает стоимость недвижимости. Сеть должна включать BatchNorm слои и Dropout (или НЕ включать, но нужно обосновать)\n",
    "4. Сравните сходимость Adam, RMSProp и SGD, сделайте вывод по качеству работы модели\n",
    "\n",
    "train-test разделение нужно сделать с помощью sklearn random_state=13, test_size = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c78c6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17a3a699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "california = fetch_california_housing()\n",
    "feature_names = california.feature_names\n",
    "data = california.data\n",
    "df = pd.DataFrame(data, columns=feature_names)\n",
    "df['target'] = california.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8cb1cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73170ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = california['data']\n",
    "y = california['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b6caef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Масштабирование\n",
    "X_sc = StandardScaler().fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78008c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15480, 8) <class 'numpy.ndarray'>\n",
      "(5160, 8) <class 'numpy.ndarray'>\n",
      "(15480,) <class 'numpy.ndarray'>\n",
      "(5160,) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=13)\n",
    "print(X_train.shape, type(X_train))\n",
    "print(X_test.shape, type(X_test))\n",
    "print(y_train.shape, type(y_train))\n",
    "print(y_test.shape, type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5536d40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCalifornia(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self,df_train, y_train):\n",
    "        \n",
    "        df_train = np.array(df_train)\n",
    "        y_train = np.array(y_train)\n",
    "        self.x=torch.from_numpy(df_train)\n",
    "        self.y = torch.from_numpy(y_train)\n",
    "        self.n_samples= df_train.shape[0]\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        return self.x[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "132d1c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_actions = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "dataset =  MyCalifornia(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f70f5b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 3.5174e+00,  3.6000e+01,  4.5479e+00,  1.0944e+00,  1.3570e+03,\n",
       "          2.0654e+00,  3.4210e+01, -1.1823e+02], dtype=torch.float64),\n",
       " tensor(2.6800, dtype=torch.float64))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_data = dataset[0]\n",
    "first_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09fd43b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3.5174e+00,  3.6000e+01,  4.5479e+00,  1.0944e+00,  1.3570e+03,\n",
      "         2.0654e+00,  3.4210e+01, -1.1823e+02], dtype=torch.float64) tensor(2.6800, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "features, labels = first_data\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dc5601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset,\n",
    "                          batch_size=4,\n",
    "                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7ce4d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MyCalifornia(X_test, y_test)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f730f71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_epochs = 10\n",
    "learning_rate = 0.1\n",
    "size_hidden= 50\n",
    "\n",
    "batch_no = len(X_train)\n",
    "cols=X_train.shape[1] \n",
    "n_output=1\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, size_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(cols, 4*size_hidden)   # hidden layer\n",
    "        self.fc2 = nn.Linear(4 * size_hidden, 2 * size_hidden)\n",
    "        self.fc3 = nn.Linear(2 * size_hidden, size_hidden)\n",
    "        self.bn = nn.BatchNorm1d(size_hidden)\n",
    "        self.dp = nn.Dropout(0.25)\n",
    "        self.predict = torch.nn.Linear(size_hidden, n_output)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = F.relu(x)      # activation function for hidden layer\n",
    "        x = self.fc2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.dp(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x\n",
    "    \n",
    "net = Net(cols, size_hidden, n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5b4da75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/recpi/anaconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "optimizer_1 = [torch.optim.Adam(net.parameters(), lr=0.1),\"Adam\"]\n",
    "optimizer_2 = [torch.optim.RMSprop(net.parameters(), lr=0.1, alpha=0.99),\"RMSprop\"]\n",
    "optimizer_4 = [torch.optim.Adagrad(net.parameters(), lr=0.1), \"Adagrad\"]\n",
    "optimizer_3 = [torch.optim.SGD(net.parameters(), lr=0.1),\"SGD\"]\n",
    "criterion = torch.nn.MSELoss(size_average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ce4a74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam\n",
      "Epoch 1 loss:  23792.753440856934 15480.0\n",
      "Epoch 2 loss:  44071.32302093506 30960.0\n",
      "Epoch 3 loss:  43361.70469665527 46440.0\n",
      "Epoch 4 loss:  45135.29837036133 61920.0\n",
      "Epoch 5 loss:  41714.28016662598 77400.0\n",
      "Epoch 6 loss:  30208.643913269043 92880.0\n",
      "Epoch 7 loss:  56417.70571899414 108360.0\n",
      "Epoch 8 loss:  32026.065399169922 123840.0\n",
      "Epoch 9 loss:  46050.5751953125 139320.0\n",
      "Epoch 10 loss:  54175.84662628174 154800.0\n",
      "15480 15480\n",
      "r2_score -17.947949640048762\n",
      "RMSprop\n",
      "Epoch 1 loss:  491598.0480270386 15480.0\n",
      "Epoch 2 loss:  807722.1161804199 30960.0\n",
      "Epoch 3 loss:  1063910.1572113037 46440.0\n",
      "Epoch 4 loss:  984378.9000701904 61920.0\n",
      "Epoch 5 loss:  1238698.4234085083 77400.0\n",
      "Epoch 6 loss:  724665.4023895264 92880.0\n",
      "Epoch 7 loss:  769299.3152694702 108360.0\n",
      "Epoch 8 loss:  747007.7965927124 123840.0\n",
      "Epoch 9 loss:  951812.1020507812 139320.0\n",
      "Epoch 10 loss:  966501.1037979126 154800.0\n",
      "15480 15480\n",
      "r2_score -8.016241555021658\n",
      "Adagrad\n",
      "Epoch 1 loss:  25455.787796020508 15480.0\n",
      "Epoch 2 loss:  18936.933349609375 30960.0\n",
      "Epoch 3 loss:  18993.54653930664 46440.0\n",
      "Epoch 4 loss:  17197.725830078125 61920.0\n",
      "Epoch 5 loss:  15447.774723052979 77400.0\n",
      "Epoch 6 loss:  14260.849521636963 92880.0\n",
      "Epoch 7 loss:  13479.668766021729 108360.0\n",
      "Epoch 8 loss:  13342.057205200195 123840.0\n",
      "Epoch 9 loss:  12475.794570922852 139320.0\n",
      "Epoch 10 loss:  12565.144371032715 154800.0\n",
      "15480 15480\n",
      "r2_score -0.635253231950619\n",
      "SGD\n",
      "Epoch 1 loss:  nan 15480.0\n",
      "Epoch 2 loss:  nan 30960.0\n",
      "Epoch 3 loss:  nan 46440.0\n",
      "Epoch 4 loss:  nan 61920.0\n",
      "Epoch 5 loss:  nan 77400.0\n",
      "Epoch 6 loss:  nan 92880.0\n",
      "Epoch 7 loss:  nan 108360.0\n",
      "Epoch 8 loss:  nan 123840.0\n",
      "Epoch 9 loss:  nan 139320.0\n",
      "Epoch 10 loss:  nan 154800.0\n",
      "15480 15480\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m pred\u001b[38;5;241m=\u001b[39mresult\u001b[38;5;241m.\u001b[39mdata[:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(pred),\u001b[38;5;28mlen\u001b[39m(y_train))\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr2_score \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr2_score(pred,y_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py:789\u001b[0m, in \u001b[0;36mr2_score\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mr2_score\u001b[39m(y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;124;03m\"\"\":math:`R^2` (coefficient of determination) regression score function.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \n\u001b[1;32m    705\u001b[0m \u001b[38;5;124;03m    Best possible score is 1.0 and it can be negative (because the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;124;03m    -3.0\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    792\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    794\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y_pred) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py:95\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m    the dtype argument passed to check_array.\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     94\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m---> 95\u001b[0m y_true \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:800\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    795\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    796\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    797\u001b[0m         )\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 800\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    803\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:114\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    108\u001b[0m         allow_nan\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misinf(X)\u001b[38;5;241m.\u001b[39many()\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(X)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m    112\u001b[0m     ):\n\u001b[1;32m    113\u001b[0m         type_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfinity\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_nan \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN, infinity\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    115\u001b[0m             msg_err\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    116\u001b[0m                 type_err, msg_dtype \u001b[38;5;28;01mif\u001b[39;00m msg_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    117\u001b[0m             )\n\u001b[1;32m    118\u001b[0m         )\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from torch.autograd import Variable\n",
    "# running_loss = 0.0\n",
    "for optimizer in [optimizer_1, optimizer_2,optimizer_4,optimizer_3]:\n",
    "    print(optimizer[1])\n",
    "    optimizer=optimizer[0]\n",
    "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        #Shuffle just mixes up the dataset between epocs\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        # Mini batch learning\n",
    "        for i in range(batch_no):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            inputs = Variable(torch.FloatTensor(X_train[start:end]))\n",
    "            labels = Variable(torch.FloatTensor(y_train[start:end]))\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            #print(\"outputs\",outputs)\n",
    "            #print(\"outputs\",outputs,outputs.shape,\"labels\",labels, labels.shape)\n",
    "            loss = criterion(outputs, torch.unsqueeze(labels,dim=1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            running_items += len(labels)\n",
    "\n",
    "\n",
    "        print('Epoch {}'.format(epoch+1), \"loss: \",running_loss, running_items)\n",
    "        running_loss = 0.0\n",
    "\n",
    "    X = Variable(torch.FloatTensor(X_train)) \n",
    "    result = net(X)\n",
    "    pred=result.data[:,0].numpy()\n",
    "    print(len(pred),len(y_train))\n",
    "    print(f\"r2_score {r2_score(pred,y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7340a763",
   "metadata": {},
   "source": [
    "без Dropout существенно теряется качество\n",
    "\n",
    "BatchNorm1d нормализация, также нормальзовал данные перед входом в сеть\n",
    "\n",
    "по цифрам видно отличие результата оптимизаторов, на мой взгляд Adam всех практичнее. SGD выдает nan на loss, не понял почему"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a050cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a97220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c01b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b603c928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3a2801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0cfd42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032bbac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4400b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e699493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2119dac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7ddb9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3905d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252283d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482e055e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de85f5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b434bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
